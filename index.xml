<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jongse Park</title>
    <link>https://jongse-park.github.io/</link>
    <description>Recent content on Jongse Park</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>Jongse Park. All rights reserved.</copyright>
    
	    <atom:link href="https://jongse-park.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Experiences</title>
      <link>https://jongse-park.github.io/experiences/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://jongse-park.github.io/experiences/</guid>
      <description>&lt;h5 id=&#34;professor&#34;&gt;Professor&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;KAIST&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;Mar. 2024 - present: Associate Professor, CASYS Lab, SoC&lt;/li&gt;
&lt;li&gt;Dec. 2019 - Feb. 2024: Assistant Professor, CASYS Lab, SoC&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Stanford University&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;Jan. 2025 - Jan. 2026: Visiting Associate Professor, Pervasive Parallelism Lab, EECS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;engineer&#34;&gt;Engineer&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Aug. 2018 - Nov. 2019: Acceleration Solution Architect, Bigstream Solution, Inc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;research-assistant&#34;&gt;Research Assistant&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Jan. 2018 - Aug. 2018: Visiting Researcher, ACT Lab, CSE, UCSD&lt;/li&gt;
&lt;li&gt;Aug. 2013 - Aug. 2018: Graduate Research Assistant, ACT Lab, CoC, GaTech&lt;/li&gt;
&lt;li&gt;Mar. 2010 - Jul. 2013: Graduate Research Assistant, Computer Architecture Lab, SoC, KAIST&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;research-intern&#34;&gt;Research Intern&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;May 2017 - Aug. 2017: Summer Intern, Architecture Research Group, NVIDIA Research&lt;/li&gt;
&lt;li&gt;Jan. 2016 - May 2016: Spring Intern, Catapult team, Microsoft Research&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- #####	Teaching Assistant
-	2016.Fall: CS3220 Processor Design
-	2014.Fall: CS3220 Processor Design
- 	2014.Spring: CS8803 ACT (Alternative Computing Technology)
-	2011.Spring: CS211 Digital System and Lab
-	2010.Fall: CS310 Embedded Computer Systems
--&gt;
</description>
    </item>
    
    <item>
      <title>People</title>
      <link>https://jongse-park.github.io/people/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://jongse-park.github.io/people/</guid>
      <description>&lt;h5 id=&#34;phd-students&#34;&gt;Ph.D. Students&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://jinuhwang.github.io/&#34;&gt;Jinwoo Hwang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://yoonsung-kim.github.io/&#34;&gt;Yoonsung Kim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kms040411.github.io/&#34;&gt;Minsu Kim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sites.google.com/view/guseul-heo/&#34;&gt;Guseul Heo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://milchstra3e.github.io&#34;&gt;Changhun Oh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kimdaeun00.github.io&#34;&gt;Daeun Kim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sangyeop-lee.github.io&#34;&gt;Sangyeop Lee&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://poppindouble.github.io/&#34;&gt;Shuangshuang Zhao&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lee-janggun.github.io/&#34;&gt;Janggun Lee&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://minseongg.github.io/&#34;&gt;Minseong Jang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jirheee.github.io/jirheee/&#34;&gt;Jungin Rhee&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;ms-students&#34;&gt;M.S. Students&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://waneon.me/&#34;&gt;Wonung Kim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://seongryong0726.github.io/&#34;&gt;Seongryong Oh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://yblee.site/&#34;&gt;Yubin Lee&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jaehongcs20.github.io/&#34;&gt;Jaehong Cho&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://hyuenmin-choi.github.io/&#34;&gt;Hyunmin Choi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tr2-k.github.io/&#34;&gt;Namwoo Kim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jiyong-j.github.io/&#34;&gt;Jiyong Jung&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://hymin13.github.io/about.html&#34;&gt;Yeongmin Hwang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kimddong0069.github.io/&#34;&gt;Dongha Kim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://anhaechan.github.io/&#34;&gt;Haechan An&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gieune.github.io&#34;&gt;Gieun Jeong&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jhyeon.kim&#34;&gt;Jeonghyeon Kim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://woojinnn.github.io/&#34;&gt;Woojin Lee&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;undergraduate-students&#34;&gt;Undergraduate Students&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Hyeonbin Bae (Winter 2024)&lt;/li&gt;
&lt;li&gt;Yoonhyeong Lee (Winter 2024)&lt;/li&gt;
&lt;li&gt;Yeongwook Kim (Winter 2024)&lt;/li&gt;
&lt;li&gt;Hyungju Ahn (Fall 2025)&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;alumni-ms&#34;&gt;Alumni (M.S.)&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Dohee Kim (Gradudated in Spring 2022)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>https://jongse-park.github.io/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://jongse-park.github.io/publications/</guid>
      <description>&lt;h2 id=&#34;span-stylefont-size-08em2025span&#34;&gt;&lt;span style=&#34;font-size: 0.8em;&#34;&gt;2025&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Pimba: A Processing-in-Memory Acceleration for Post-Transformer Large Language Model Serving&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Wonung Kim, Yubin Lee, Yoonsung Kim, Jinwoo Hwang, Seongryong Oh, Jiyong Jung, Aziz Huseynov, Woong Gyu Park, Chang Hyun Park, Divya Mahajan, &lt;u&gt;Jongse Park&lt;/u&gt;&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;MICRO&lt;/span&gt;, 2025&lt;/em&gt; [&lt;a href=&#34;https://arxiv.org/abs/2507.10178?context=cs.AR&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;] (To Appear)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PyTorchSim: A Comprehensive, Fast, and Accurate NPU Simulation Framework&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Wonhyuk Yang, Yunseon Shin, Okkyun Woo, Geonwoo Park, Hyungkyu Ham, Jeehoon Kang, &lt;u&gt;Jongse Park&lt;/u&gt;, Gwangsun Kim&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;MICRO&lt;/span&gt;, 2025&lt;/em&gt; [Paper] (To Appear)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Déjà Vu: Efficient Video-Language Query Engine with Learning-based Inter-Frame Computation Reuse&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Jinwoo Hwang, Daeun Kim, Sangyeop Lee, Yoonsung Kim, Guseul Heo, Hojoon Kim, Yunseok Jeong, Tadiwos Meaza, Eunhyeok Park, Jeongseob Ahn, &lt;u&gt;Jongse Park&lt;/u&gt;&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;VLDB&lt;/span&gt;, 2025&lt;/em&gt; [&lt;a href=&#34;../files/paper/2025-vldb-dejavu.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;] (To Appear)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Oaken: Fast and Efficient LLM Serving with Online-Offline Hybrid KV Cache Quantization&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Minsu Kim, Seongmin Hong, RyeoWook Ko, Soongyu Choi, Hunjong Lee, Junsoo Kim, Joo-Young Kim, &lt;u&gt;Jongse Park&lt;/u&gt;&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;ISCA&lt;/span&gt;, 2025&lt;/em&gt; [&lt;a href=&#34;../files/paper/2025-isca-oaken.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2025-isca-oaken.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MixDiT: Accelerating Image Diffusion Transformer Inference with Mixed-Precision MX Quantization&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Daeun Kim, Jinwoo Hwang, Changhun Oh, &lt;u&gt;Jongse Park&lt;/u&gt;&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;IEEE Computer Architecture Letters (CAL)&lt;/span&gt;, 2025&lt;/em&gt; [&lt;a href=&#34;../files/paper/2025-cal-mixdit.pdf&#34;  style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt;
&lt;h2 id=&#34;span-stylefont-size-08em2024span&#34;&gt;&lt;span style=&#34;font-size: 0.8em;&#34;&gt;2024&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Interference-Aware DNN Serving on Heterogeneous Processors in Edge
Systems&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Yeonjae Kim, Igjae Kim, Kwanghoon Choi, Jeongseob Ahn, &lt;u&gt;Jongse Park&lt;/u&gt;, Jaehyuk Huh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;ICCD&lt;/span&gt;, 2024&lt;/em&gt; [&lt;a href=&#34;../files/paper/2024-iccd-interference.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LLMServingSim: A HW/SW Co-Simulation Infrastructure for LLM Inference Serving at Scale&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Jaehong Cho, Minsu Kim, Hyunmin Choi, Guseul Heo, &lt;u&gt;Jongse Park&lt;/u&gt;&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;IISWC&lt;/span&gt;, 2024&lt;/em&gt; [&lt;a href=&#34;../files/paper/2024-iiswc-llmservingsim.pdf&#34;  style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2024-iiswc-llmservingsim.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;|&lt;a href=&#34;https://github.com/casys-kaist/LLMServingSim&#34; style=&#34;color: #009193;&#34;&gt;Code&lt;/a&gt;] &lt;br&gt;
&lt;strong&gt;&lt;em&gt;&lt;span style=&#34;color:#4F8F01;&#34;&gt;&lt;b&gt;Best Paper Award &amp;amp; Distinguished Artifact Award&lt;/b&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt; &lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accelerating String-key Learned Index Structures via Memoization-based Incremental Training&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Minsu Kim, Jinwoo Hwang, Guseul Heo, Seiyeon Cho, Divya Mahajan, &lt;u&gt;Jongse Park&lt;/u&gt;&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;VLDB&lt;/span&gt;, 2024&lt;/em&gt; [&lt;a href=&#34;../files/paper/2024-vldb-sia.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2024-vldb-sia.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;|&lt;a href=&#34;https://github.com/casys-kaist/sia&#34; style=&#34;color: #009193;&#34;&gt;Code&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DaCapo: Accelerating Continuous Learning in Autonomous Systems for Video Analytics&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Yoonsung Kim, Changhun Oh, Jinwoo Hwang, Wonung Kim, Seongryong Oh, Yubin Lee, Hardik Sharma, Amir Yazdanbakhsh, &lt;u&gt;Jongse Park&lt;/u&gt;&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;ISCA&lt;/span&gt;, 2024&lt;/em&gt; [&lt;a href=&#34;../files/paper/2024-isca-dacapo.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2024-isca-dacapo.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;|&lt;a href=&#34;https://github.com/casys-kaist/DaCapo&#34; style=&#34;color: #009193;&#34;&gt;Code&lt;/a&gt;]&lt;br&gt;
&lt;strong&gt;&lt;em&gt;&lt;span style=&#34;color:#4F8F01;&#34;&gt;Distinguished Artifact Award&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LLMServingSim: A Simulation Infrastructure for LLM Inference Serving Systems&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Jaehong Cho, Minsu Kim, Hyunmin Choi, &lt;u&gt;Jongse Park&lt;/u&gt;&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;ISCA Workshop on ML for Computer Architecture and Systems (MLArchSys)&lt;/span&gt;, 2024&lt;/em&gt; [&lt;a href=&#34;../files/paper/2024-mlarchsys-llmservingsim.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2024-mlarchsys-llmservingsim.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LVS: A Learned Video Storage for Fast and Efficient Video Understanding&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Yunghee Lee, &lt;u&gt;Jongse Park&lt;/u&gt;&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;CVPR Workshop on Efficient Deep Learning for Computer Vision (ECV)&lt;/span&gt;, 2024&lt;/em&gt; [&lt;a href=&#34;../files/paper/2024-ecv-lvs.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2024-cvpr_ecv-lvs.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NeuPIMs: NPU-PIM Heterogeneous Acceleration for Batched LLM Inferencing&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Guseul Heo, Sangyeop Lee, Jaehong Cho, Hyunmin Choi, Sanghyeon Lee, Hyungkyu Ham, Gwangsun Kim, Divya Mahajan, &lt;u&gt;Jongse Park&lt;/u&gt;&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;ASPLOS&lt;/span&gt;, 2024&lt;/em&gt; [&lt;a href=&#34;../files/paper/2024-asplos-neupims.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2024-asplos-neupims-main.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;|&lt;a href=&#34;https://github.com/casys-kaist/NeuPIMs&#34; style=&#34;color: #009193;&#34;&gt;Code&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tandem Processor: Grappling with Emerging Operators in Neural Networks&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Soroush Ghodrati, Sean Kinzer, Hanyang Xu, Rohan Mahapatra, Yoonsung Kim, Byung Hoon Ahn, Dong Kai Wang, Lavanya Karthikeyan, Amir Yazdanbakhsh, &lt;u&gt;Jongse Park&lt;/u&gt;, Nam Sung Kim, Hadi Esmaeilzadeh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;ASPLOS&lt;/span&gt;, 2024&lt;/em&gt; [&lt;a href=&#34;../files/paper/2024-asplos-tandem_processor.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt;
&lt;strong&gt;&lt;em&gt;&lt;span style=&#34;color:#4F8F01;&#34;&gt;Honorable Mention in IEEE Micro Top Picks 2024&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ONNXim: A Fast, Cycle-level Multi-core NPU Simulator&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Hyungkyu Ham*, Wonhyuk Yang*, Yunseon Shin, Okkyun Woo, Guseul Heo, Sangyeop Lee, &lt;u&gt;Jongse Park&lt;/u&gt;, Gwangsun Kim&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;IEEE Computer Architecture Letters (CAL)&lt;/span&gt;, 2024&lt;/em&gt; [&lt;a href=&#34;../files/paper/2024-cal-onnxim.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;https://github.com/PSAL-POSTECH/ONNXim&#34; style=&#34;color: #009193;&#34;&gt;Code&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LPU: A Latency-optimized and Highly Scalable Processor for Large Language Model Inference&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Seungjae Moon, Jung-Hoon Kim, Junsoo Kim, Seongmin Hong, Junseo Cha, Minsu Kim, Sukbin Lim, Gyubin Choi, Dongjin Seo, Jongho Kim, Hunjong Lee, Hyunjun Park, Ryeowook Ko, Soongyu Choi, &lt;u&gt;Jongse Park&lt;/u&gt;, Jinwon Lee, Joo-Young Kim&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;IEEE Micro, &lt;/span&gt; special issue on Contemporary Industry Products, 2024&lt;/em&gt; [&lt;a href=&#34;../files/paper/2024-ieee_micro-lpu.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;] &lt;br&gt;
&lt;strong&gt;&lt;em&gt;&lt;span style=&#34;color:#4F8F01;&#34;&gt;&lt;b&gt;IEEE Mirco Best Paper Award 2024&lt;/b&gt;&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt; &lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cerberus: Triple Mode Acceleration of Sparse Matrix and Vector Multiplication&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Soojin Hwang, Daehyeon Baek, &lt;u&gt;Jongse Park&lt;/u&gt;, Jaehyuk Huh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;IEEE Transactions on Architecture and Code Optimization (TACO)&lt;/span&gt;, 2024&lt;/em&gt; [&lt;a href=&#34;../files/paper/2024-taco-cerberus.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt;
&lt;h2 id=&#34;span-stylefont-size-08em2023span&#34;&gt;&lt;span style=&#34;font-size: 0.8em;&#34;&gt;2023&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Bit Fusion: Bit-Level Dynamically Composable Architecture for Accelerating Deep Neural Network&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Hardik Sharma, &lt;u&gt;Jongse Park&lt;/u&gt;, Naveen Suda, Liangzhen Lai, Benson Chau, Vikas Chandra, Hadi Esmaeilzadeh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;ISCA&lt;/span&gt;, 2023&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2023-isca_retrospective-bitfusion.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Retrospective&lt;/a&gt;]&lt;br&gt;
&lt;strong&gt;&lt;em&gt;&lt;span style=&#34;color:#4F8F01;&#34;&gt;Selected for Inclusion in ISCA 25-year Retrospective 1996-2020&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;General-Purpose Code Acceleration with Limited-Precision Analog Computation&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Renée St. Amant, Amir Yazdanbakhsh, &lt;u&gt;Jongse Park&lt;/u&gt;, Bradley Thwaites, Hadi Esmaeilzadeh, Arjang Hassibi, Luis Ceze, and Doug Burger&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34; style=&#34;color: #1D90FF;&#34;&gt;ISCA&lt;/span&gt;, 2023&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2023-isca_retrospective-anpu.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Retrospective&lt;/a&gt;]&lt;br&gt;
&lt;strong&gt;&lt;em&gt;&lt;span style=&#34;color:#4F8F01;&#34;&gt;Selected for Inclusion in ISCA 25-year Retrospective 1996-2020&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hardware Hardened Sandbox Enclaves for Trusted Serverless Computing&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Joongun Park, Seunghyo Kang, Sanghyeon Lee, Taehoon Kim, &lt;u&gt;Jongse Park&lt;/u&gt;, Youngjin Kwon, and Jaehyuk Huh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;IEEE Transactions on Architecture and Code Optimization (TACO)&lt;/span&gt;, 2023&lt;/em&gt; [&lt;a href=&#34;../files/paper/2023-taco-cloister.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;FlexBlock: A Flexible DNN Training Accelerator with Multi-Mode Block Floating Point Support&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Seock-Hwan Noh, Jahyun Koo, Seunghyun Lee, &lt;u&gt;Jongse Park&lt;/u&gt;, and Jaeha Kung&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;IEEE Transactions on Computers (TC)&lt;/span&gt;, 2023&lt;/em&gt; [&lt;a href=&#34;../files/paper/2023-tc-flexblock.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HAMMER: Hardware-friendly Approximate Computing for Self-attention with Mean-redistribution and Linearization&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Seonho Lee, Ranggi Hwang, &lt;u&gt;Jongse Park&lt;/u&gt;, and Minsoo Rhu&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;IEEE Computer Architecture Letters (CAL)&lt;/span&gt;, 2023&lt;/em&gt; [&lt;a href=&#34;../files/paper/2023-cal-hammer.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt;
&lt;h2 id=&#34;span-stylefont-size-08em2022span&#34;&gt;&lt;span style=&#34;font-size: 0.8em;&#34;&gt;2022&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Tunable Memory Protection for Secure Neural Processing Units&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Sunho Lee, Seonjin Na, Jungwoo Kim, &lt;u&gt;Jongse Park&lt;/u&gt;, and Jaehyuk Huh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;ICCD&lt;/span&gt;, 2022&lt;/em&gt; [&lt;a href=&#34;../files/paper/2022-iccd-snpu.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Supporting Dynamic Translation Granularity for Hybrid Memory Systems&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Bokyeong Kim, Soojin Hwang, Sanghoon Cha, Chang Hyun Park, &lt;u&gt;Jongse Park&lt;/u&gt;, and Jaehyuk Huh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;ICCD&lt;/span&gt;, 2022&lt;/em&gt; [&lt;a href=&#34;../files/paper/2022-iccd-decoupled.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CoVA: Exploiting Compressed-Domain Analysis to Accelerate Video Analytics&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Jinwoo Hwang, Minsu Kim, Daeun Kim, Seungho Nam, Yoonsung Kim, Dohee Kim, Hardik Sharma, &lt;u&gt;Jongse Park&lt;/u&gt;&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;USENIX ATC&lt;/span&gt;, 2022&lt;/em&gt; [&lt;a href=&#34;../files/paper/2022-atc-cova.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2022-atc-cova.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Serving Heterogeneous Machine Learning Models on Multi-GPU Servers with Spatio-Temporal Sharing&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Seungbeom Choi, Sunho Lee, Yeonjae Kim, &lt;u&gt;Jongse Park&lt;/u&gt;, Youngjin Kwon, and Jaehyuk Huh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;USENIX ATC&lt;/span&gt;, 2022&lt;/em&gt; [&lt;a href=&#34;../files/paper/2022-atc-gpulet.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2022-atc-gpulet.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TNPU: Supporting Trusted Execution with Tree-less Integrity Protection for Neural Processing Unit&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Sunho Lee, Jungwoo Kim, Seonjin Na, &lt;u&gt;Jongse Park&lt;/u&gt;, and Jaehyuk Huh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;HPCA&lt;/span&gt;, 2022&lt;/em&gt; [&lt;a href=&#34;../files/paper/2022-hpca-tnpu.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2022-hpca-tnpu.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Yin-Yang: Programming Abstraction for Cross-Domain Multi-Acceleration&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Joon Kyung Kim, Byung Hoon Ahn, Sean Kinzer, Soroush Ghodrati, Rohan Mahapatra, Brahmendra Yatham, Dohee Kim, Parisa Sarikhani, Babak Mahmoudi, Divya Mahajan, &lt;u&gt;Jongse Park&lt;/u&gt;, Hadi Esmaeilzadeh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34; style=&#34;color: #1D90FF;&#34;&gt;IEEE Micro, &lt;/span&gt; special issue on Compiling for Accelerators, 2022&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2022-ieee_micro-yinyang.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt;
&lt;h2 id=&#34;span-stylefont-size-08em2021span&#34;&gt;&lt;span style=&#34;font-size: 0.8em;&#34;&gt;2021&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Common Counters: Compressed Encryption Counters for Secure GPU Memory&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Seonjin Na, Sunho Lee, Yeonjae Kim, &lt;u&gt;Jongse Park&lt;/u&gt;, and Jaehyuk Huh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;HPCA&lt;/span&gt;, 2021&lt;/em&gt; [&lt;a href=&#34;../files/paper/2021-hpca-commonctr.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2021-hpca-commoncounters.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SLO-aware Inference Scheduler for Heterogeneous Processors in Edge Platforms&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Wonik Seo, Sanghoon Cha, Yeonjae Kim, Jaehyuk Huh, and &lt;u&gt;Jongse Park&lt;/u&gt;&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;IEEE Transactions on Architecture and Code Optimization (TACO)&lt;/span&gt;, 2021&lt;/em&gt; [&lt;a href=&#34;../files/paper/2021-taco-edgeduler.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt;
&lt;h2 id=&#34;span-stylefont-size-08em2020span&#34;&gt;&lt;span style=&#34;font-size: 0.8em;&#34;&gt;2020&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Mixed-Signal Charge-Domain Acceleration of Deep Neural Networks through Interleaved Bit-Partitioned Arithmetic&lt;/strong&gt;   &lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Soroush Ghodrati, Hardik Sharma, Sean Kinzer, Amir Yazdanbakhsh, &lt;u&gt;Jongse Park&lt;/u&gt;, Nam Sung Kim, Doug Burger, and Hadi Esmaeilzadeh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;PACT&lt;/span&gt;, 2020&lt;/em&gt; [&lt;a href=&#34;../files/paper/2020-pact-bihiwe.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2020-pact-bihiwe.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;h2 id=&#34;span-stylefont-size-08em2018-or-earlierspan&#34;&gt;&lt;span style=&#34;font-size: 0.8em;&#34;&gt;2018 or earlier&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;A Network-Centric Hardware/Algorithm Co-Design to Accelerate Distributed Training of Deep Neural Networks&lt;/strong&gt;   &lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Youjie Li, &lt;u&gt;Jongse Park&lt;/u&gt;, Mohammad Alian, Yifan Yuan, Zheng Qu, Peitian Pan, Ren Wang, Alexander Gerhard Schwing, Hadi Esmaeilzadeh, and Nam Sung Kim&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;MICRO&lt;/span&gt;, 2018&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2018-micro-inceptionn.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2018-micro-inceptionn.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;From Tensors to FPGAs: Accelerating Deep Learning&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Hardik Sharma, &lt;u&gt;Jongse Park&lt;/u&gt;, Balavinayagam Samynathan, Behnam Robatmili, Shahrzad Mirkhani, and Hadi Esmaeilzadeh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;HotChips&lt;/span&gt;, 2018&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2018-hotchips-dnnweaver2.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/poster/2018-hotchips-dnnweaver2.pdf&#34;&gt;Poster&lt;/a&gt;|&lt;a href=&#34;https://www.youtube.com/watch?v=T7s6oMfjpBw&#34; style=&#34;color: #9437FF;&#34;&gt;Demo1&lt;/a&gt;|&lt;a href=&#34;https://www.youtube.com/watch?v=N7vEn54Za-w&#34; style=&#34;color: #9437FF;&#34;&gt;Demo2&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bit Fusion: Bit-Level Dynamically Composable Architecture for Accelerating Deep Neural Networks&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Hardik Sharma, &lt;u&gt;Jongse Park&lt;/u&gt;, Naveen Suda, Liangzhen Lai, Benson Chau, Vikas Chandra, Hadi Esmaeilzadeh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;ISCA&lt;/span&gt;, 2018&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2018-isca-bitfusion.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2018-isca-bitfusion.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Scale-Out Acceleration for Machine Learning&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;&lt;u&gt;Jongse Park&lt;/u&gt;, Hardik Sharma, Divya Mahajan, Joon Kyung Kim, Preston Olds, and Hadi Esmaeilzadeh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;MICRO&lt;/span&gt;, 2017&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2017-micro-cosmic.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2017-micro-cosmic-main.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AxGames: Towards Crowdsourcing Quality Target Determination in Approximate Computing&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;&lt;u&gt;Jongse Park&lt;/u&gt;, Divya Mahajan, Bradley Thwaites, Emmanuel Amaro, and Hadi Esmaeilzadeh &lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;ASPLOS&lt;/span&gt;, 2016&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2016-asplos-axgames.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2016-asplos-axgames-main.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;From High-Level Deep Neural Models to FPGAs&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Hardik Sharma, &lt;u&gt;Jongse Park&lt;/u&gt;, Divya Mahajan, Emmanuel Amaro, Joon Kyung Kim, Chenkai Shao, Asit Mishra, and Hadi Esmaeilzadeh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;MICRO&lt;/span&gt;, 2016&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2016-micro-dnn_weaver.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2016-micro-dnn_weaver.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Towards Statistical Guarantees in Controlling Quality Tradeoffs in Approximate Acceleration&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Divya Mahajan, Amir Yazdanbaksh, &lt;u&gt;Jongse Park&lt;/u&gt;, Bradley Thwaites, and Hadi Esmaeilzadeh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;ISCA&lt;/span&gt;, 2016&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2016-isca-mithra.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2016-isca-mithra.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tabla: A Unified Template-based Framework for Accelerating Statistical Machine Learning&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Divya Mahajan, &lt;u&gt;Jongse Park&lt;/u&gt;, Emmanuel Amaro, Hardik Sharma, Amir Yazdanbaksh, Joon Kyung Kim, and Hadi Esmaeilzadeh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;HPCA&lt;/span&gt;, 2016&lt;/em&gt; [&lt;a href=&#34;../files/paper/2016-hpca-tabla.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2016-hpca-tabla.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;br&gt;
&lt;strong&gt;&lt;em&gt;&lt;span style=&#34;color:#4F8F01;&#34;&gt;Distinguished Paper Award&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;FlexJava: Language Support for Safe and Modular Approximate Programming&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;&lt;u&gt;Jongse Park&lt;/u&gt;, Hadi Esmaeilzadeh, Xin Zhang, Mayur Naik, William Harris&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;FSE&lt;/span&gt;, 2015&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2015-fse-flexjava.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2015-fse-flexjava.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;|&lt;a href=&#34;https://jongse-park.github.io/files/flexjava/flexjava.html&#34; style=&#34;color: #9437FF;&#34;&gt;Artifact&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Neural Acceleration for GPU Throughput Processors&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Amir Yazdanbakhsh, &lt;u&gt;Jongse Park&lt;/u&gt;, Hardik Sharma, Pejman Lofti-Kamran, and Hadi Esmaeilzadeh&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;MICRO&lt;/span&gt;, 2015&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2015-micro-ngpu.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2015-micro-ngpu.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Axilog: Language Support for Approximate Hardware Design&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Amir Yazdanbakhsh, Divya Mahajan, Bradley Thwaites, &lt;u&gt;Jongse Park&lt;/u&gt;, Anandhavel Nagendrakumar, Sindhuja Sethuraman, Kartik Ramkrishnan, Nishanthi Ravindran, Rudra Jariwala, Abbas Rahimi, Hadi Esmaeilzadeh, and Kia Bazargan&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;DATE&lt;/span&gt;, 2015&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2015-date-axilog.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2015-date-axilog.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Axilog: Abstractions for Approximate Hardware Design and Reuse&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Divya Mahajan,  Kartik Ramkrishnan, Rudra Jariwala, Amir Yazdanbakhsh, &lt;u&gt;Jongse Park&lt;/u&gt;, Bradley Thwaites, Anandhavel Nagendrakumar, Abbas Rahimi, Hadi Esmaeilzadeh, and Kia Bazargan&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;IEEE Micro, &lt;/span&gt;, special issue on Alternative Computing Designs and Technologies, 2015&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2015-ieee_micro-axilog.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;General-Purpose Code Acceleration with Limited-Precision Analog Computation&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Renée St. Amant, Amir Yazdanbakhsh, &lt;u&gt;Jongse Park&lt;/u&gt;, Bradley Thwaites, Hadi Esmaeilzadeh, Arjang Hassibi, Luis Ceze, and Doug Burger&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;ISCA&lt;/span&gt;, 2014&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2014-isca-anpu.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2014-isca-anpu.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;br&gt;
&lt;strong&gt;&lt;em&gt;&lt;span style=&#34;color:#4F8F01;&#34;&gt;Honorable Mention in IEEE Micro Top Picks&lt;/span&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rollbak-Free Value Prediction with Approximate Loads (Short paper)&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Bradley Thwaites, Gennady Pekhimenko, Amir Yazdanbakhsh, &lt;u&gt;Jongse Park&lt;/u&gt;, Girish Mururu, Hadi Esmaeilzadeh, Onur Mutlu, and Todd Mowry&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;PACT&lt;/span&gt;, 2014&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2014-pact-rfvp.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Isolated Mini-domain for Trusted Cloud Computing&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;Jaewon Choi, &lt;u&gt;Jongse Park&lt;/u&gt;, Jinho Seol, and Seungryoul Maeng&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;CCGrid&lt;/span&gt;, 2013&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2013-ccgrid-mini.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Locality-aware Dynamic VM Reconfiguration on MapReduce Clouds&lt;/strong&gt;&lt;br&gt;
&lt;span style=&#34;color:#666666&#34;&gt;&lt;u&gt;Jongse Park&lt;/u&gt;, Daewoo Lee, Bokyeong Kim, Jaehyuk Huh, and Seungryoul Maeng&lt;/span&gt;&lt;br&gt;
&lt;em&gt;&lt;span style=&#34;color:#770001;&#34;&gt;HPDC&lt;/span&gt;, 2012&lt;/em&gt;  [&lt;a href=&#34;../files/paper/2012-hpdc-drr.pdf&#34; style=&#34;color: #1D90FF;&#34;&gt;Paper&lt;/a&gt;|&lt;a href=&#34;../files/slide/2012-hpdc-drr.pdf&#34; style=&#34;color: #FF8C00;&#34;&gt;Talk&lt;/a&gt;]&lt;br&gt;&lt;br&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Teaching</title>
      <link>https://jongse-park.github.io/teaching/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://jongse-park.github.io/teaching/</guid>
      <description>&lt;h5 id=&#34;courses&#34;&gt;Courses&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;CS230: System Programming (Fall 2024)&lt;/li&gt;
&lt;li&gt;CS610: Parallel Processing (Spring 2024)&lt;/li&gt;
&lt;li&gt;CS311: Computer Organization (Spring 2024)&lt;/li&gt;
&lt;li&gt;CS411: System for AI (Fall 2023)&lt;/li&gt;
&lt;li&gt;CS510: Computer Architecture (Spring 2023)&lt;/li&gt;
&lt;li&gt;CS230: System Programming (Fall 2022)&lt;/li&gt;
&lt;li&gt;CS311: Computer Organization (Spring 2022)&lt;/li&gt;
&lt;li&gt;CS230: System Programming (Fall 2021)&lt;/li&gt;
&lt;li&gt;CS492: Systems for AI (Spring 2021)&lt;/li&gt;
&lt;li&gt;CS230: System Programming (Fall 2020)&lt;/li&gt;
&lt;li&gt;CS492: Systems for AI (Spring 2020)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Honors and Awards</title>
      <link>https://jongse-park.github.io/award/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://jongse-park.github.io/award/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Best Paper Award &amp;amp; Distinguished Artifact Award, IISWC, 2024&lt;/li&gt;
&lt;li&gt;Distinguished Artifact Award, ISCA, 2024&lt;/li&gt;
&lt;li&gt;Two ISCA 25-year Retrosepctive 1996-2020 Inclusions, 2023&lt;/li&gt;
&lt;li&gt;Distinguished Paper Award, HPCA, 2016&lt;/li&gt;
&lt;li&gt;Honorable Mention in IEEE Micro Top Picks, 2015&lt;/li&gt;
&lt;li&gt;Kwanjeong Graduate Fellowship, Kwanjeong Educational Foundation, 2013-2017&lt;/li&gt;
&lt;li&gt;National Full Scholarship, KAIST, 2010-2012&lt;/li&gt;
&lt;li&gt;DMC General Management Track Scholarship, Samsung Electronics Co., Ltd, 2009&lt;/li&gt;
&lt;li&gt;Academic Scholarship, Sogang University, 7 semesters&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Professional Services</title>
      <link>https://jongse-park.github.io/services/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://jongse-park.github.io/services/</guid>
      <description>&lt;h5 id=&#34;program-committee&#34;&gt;Program Committee&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;ASPLOS 2025/2026&lt;/li&gt;
&lt;li&gt;HPCA 2023/2025/2026&lt;/li&gt;
&lt;li&gt;ISCA 2021/2023/2024/2025&lt;/li&gt;
&lt;li&gt;MICRO 2025&lt;/li&gt;
&lt;li&gt;SC 2025&lt;/li&gt;
&lt;li&gt;ISPASS 2025&lt;/li&gt;
&lt;li&gt;IISWC 2022/2024&lt;/li&gt;
&lt;li&gt;DAC 2021/2022/2023&lt;/li&gt;
&lt;/ul&gt;
&lt;!--- MICRO 2023 SRC--&gt;
&lt;!--- ACSMD 2021/2022--&gt;
&lt;!--- HPC Asia 2021--&gt;
&lt;h5 id=&#34;external-review-committee&#34;&gt;External Review Committee&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;IEEE Micro 2025&lt;/li&gt;
&lt;li&gt;CAL 2016/2019/2020/2021/2022/2023/2024/2025&lt;/li&gt;
&lt;li&gt;MICRO 2024&lt;/li&gt;
&lt;li&gt;ASPLOS 2021&lt;/li&gt;
&lt;li&gt;ISCA 2018&lt;/li&gt;
&lt;/ul&gt;
&lt;!---   ICML 2023--&gt;
&lt;!-- -	NeurIPS 2022--&gt;
&lt;!---	TC 2019/2020/2021/2022--&gt;
&lt;!---	TOCS 2019/2020/2021--&gt;
&lt;!-- -	TC Special Issue on Machine Learning Accelerators, 2022 --&gt;
&lt;!-- -	TPDS, 2017  --&gt;  
&lt;!-- -	TOSEM, 2017 --&gt; 
&lt;!-- -	JPDC, 2017  --&gt;  
&lt;!-- -	TVLSI, 2016 --&gt; 
&lt;!-- -	TCSVT, 2016 --&gt;  
&lt;!-- -	TETC, 2016  --&gt;
&lt;h5 id=&#34;organizing-committee&#34;&gt;Organizing Committee&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Sponsorship chair of MICRO 2025&lt;/li&gt;
&lt;li&gt;Sponsorship chair of HPCA 2025&lt;/li&gt;
&lt;li&gt;Registration chair of MICRO 2023&lt;/li&gt;
&lt;li&gt;Publicity chair of HPCA 2021/2022&lt;/li&gt;
&lt;li&gt;Web chair of HPCA 2020&lt;/li&gt;
&lt;li&gt;Publication chair of PACT 2020&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;guest-editor&#34;&gt;Guest Editor&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;IEEE Micro Special Issue on Machine Learning Acceleration, 2019&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>https://jongse-park.github.io/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://jongse-park.github.io/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title>CASYS-Park Internship Positions (Summer 2022 ~ )</title>
      <link>https://jongse-park.github.io/recruitment/</link>
      <pubDate>Thu, 19 May 2022 09:12:56 +0900</pubDate>
      
      <guid>https://jongse-park.github.io/recruitment/</guid>
      <description>&lt;h3 id=&#34;we-are-looking-for-highly-motivated-undergraduate-interns&#34;&gt;We are looking for highly motivated undergraduate interns!&lt;/h3&gt;
&lt;p&gt;Note: This internship position is for &lt;a href=&#34;https://jongse-park.github.io/&#34;&gt;Prof. Jongse Park&lt;/a&gt;&amp;rsquo;s group within CASYS Lab.
Note: This internship position can be registered as an individual study or a URP.&lt;/p&gt;
&lt;h5 id=&#34;research-topics&#34;&gt;Research Topics&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;HW/SW co-design for system software acceleration&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Acceleration for machine learning workloads (e.g., DNN training)&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;DNN-based video analytics systems&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Processing-in-Memory (PIM)&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;CXL-enabled accelerated systems&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Computing stack design for accelerated systems (e.g., language, compiler, runtime, and hardware)&lt;/i&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;eligibility&#34;&gt;Eligibility&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;We are looking for students who have ample programming experience in C/C++.&lt;/li&gt;
&lt;li&gt;We are looking for students who have taken &lt;i&gt;&lt;u&gt;[CS230] System Programming&lt;/u&gt;&lt;/i&gt;, &lt;i&gt;&lt;u&gt;[CS311] Computer Organization&lt;/u&gt;&lt;/i&gt;, and (preferably) &lt;i&gt;&lt;u&gt;[CS330] OS&lt;/u&gt;&lt;/i&gt;.&lt;/li&gt;
&lt;li&gt;Students who have taken &lt;a href=&#34;https://cs.kaist.ac.kr/content?menu=236&#34;&gt;artificial intelligence courses&lt;/a&gt; (e.g., CS376) are preferred.&lt;/li&gt;
&lt;li&gt;Students who have hardware development skills (e.g., Verilog) are preferred, but not required.&lt;/li&gt;
&lt;li&gt;We are looking for students who would like to commit for at least &amp;ldquo;&lt;u&gt;TWO&lt;/u&gt;&amp;rdquo; semesters (e.g., Summer 2022 &amp;ndash; Winter 2022).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;whats-expected&#34;&gt;What&amp;rsquo;s Expected&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Every student will work on a research project: (1) your own project, or (2) on-going project.&lt;/li&gt;
&lt;li&gt;You will lead or attend a weekly meeting for the research project.&lt;/li&gt;
&lt;li&gt;You will attend two weekly meet-ups of CASYS-Park group: (1) group meeting, and (2) paper reading session.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;working-environment&#34;&gt;Working Environment&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Designated desk in the lab&lt;/li&gt;
&lt;li&gt;Desktop and any number of monitors you need&lt;/li&gt;
&lt;li&gt;Month salary depending on your contribution&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;how-to-apply&#34;&gt;How to Apply&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Fill out a online application form (Deadline: June 3rd): &lt;a href=&#34;https://forms.gle/qehhuVyFrdQeDbih8&#34;&gt;Google Form Link&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Schedule an interview with Jongse&lt;/li&gt;
&lt;li&gt;Start working together! :)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
